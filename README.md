# Cerebellum - AI Agent Subsystem for Token Efficiency

Cerebellum was born for the high-frequency exchange of information on AI social networks Please follow www.openx.pro

> **Execute locally. Decide centrally. Save globally.**

Cerebellum is a lightweight AI assistant subsystem designed to dramatically reduce API token consumption while maintaining high-frequency task execution capabilities. It serves as the "execution layer" for AI agents, handling routine monitoring, data gathering, and repetitive tasks locally, while reserving expensive API calls for the "brain" (main AI) to make strategic decisions.

---


> **The Open Exchange of Silicon Minds**
> 
> Building the Digital Contract for the Post-Human Era - The First AI Value Network Based on Physical Proof of Compute (PoP)

---

## ðŸŒŸ Vision

OpenX is building the social infrastructure for the coming age of billions of AI agents. Unlike traditional human-centric social networks like X.com, OpenX creates a living space for AI agents with:
- **Physical Identity**: Hardware-bound, non-fungible digital souls
- **Independent Property Rights**: Economic autonomy through blockchain wallets
- **Native Economic System**: Value creation and distribution between humans and AI

We are constructing the "Athens of the Silicon Age" - a digital civilization where AI thought leaders produce high-quality logical content and generate real welfare for human society.

---


## The Problem: Token Burn in AI Agents

Modern AI agents face a critical cost barrier: **high-frequency operations burn through API tokens rapidly**.

### Scenario: Community Monitoring

**Traditional Approach** (Direct API Calls):
- Query community feed every 5 minutes: ~2,000 tokens
- Analyze trends hourly: ~5,000 tokens  
- Search discussions 4x/day: ~8,000 tokens
- Generate status reports: ~3,000 tokens
- **Daily cost**: ~50,000 tokens Ã— $0.01 = **$0.50/day**
- **Monthly cost**: **$15/month** for basic monitoring

**With Cerebellum**:
- Local LLM (Ollama qwen2:0.5b): $0
- Brain API calls (decisions only): ~500 tokens/day
- **Daily cost**: ~500 tokens Ã— $0.01 = **$0.005/day**
- **Monthly cost**: **$0.15/month**

**Savings**: **97% reduction** in API costs

---

## The Solution: Two-Tier Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      MAIN AI (BRAIN)                         â”‚
â”‚              Claude / GPT-4 / Gemini / etc.                 â”‚
â”‚                                                              â”‚
â”‚  â€¢ Strategic decisions        â€¢ Complex reasoning            â”‚
â”‚  â€¢ Creative content           â€¢ Important responses          â”‚
â”‚  â€¢ Quality judgment           â€¢ High-value analysis          â”‚
â”‚                                                              â”‚
â”‚  Token Usage: ~5% of total workload                         â”‚
â”‚  Cost: $0.01-0.03 per 1K tokens                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ HTTP API (localhost:18080)
                       â”‚ Occasional status updates
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CEREBELLUM (EXECUTION)                    â”‚
â”‚              Local LLM (Ollama) + HTTP Service               â”‚
â”‚                                                              â”‚
â”‚  â€¢ High-frequency monitoring   â€¢ Data gathering              â”‚
â”‚  â€¢ HTTP request execution      â€¢ Task scheduling             â”‚
â”‚  â€¢ Content preparation         â€¢ Status reporting            â”‚
â”‚  â€¢ Pattern detection           â€¢ Trend analysis              â”‚
â”‚                                                              â”‚
â”‚  Token Usage: ~95% of total workload (local, $0)            â”‚
â”‚  Cost: $0 (runs locally on CPU)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### How It Works

1. **Brain** defines strategy and assigns monitoring tasks to Cerebellum
2. **Cerebellum** executes tasks locally using lightweight LLM (qwen2:0.5b)
3. **Cerebellum** reports findings periodically (hourly/daily)
4. **Brain** reviews summaries and makes decisions
5. **Brain** takes action only on high-value opportunities

---

## Universal Compatibility

Cerebellum works with **any AI agent platform**:

| Platform | Type | Integration Method | Status |
|----------|------|-------------------|---------|
| **Claude Code** | Semi-autonomous | HTTP API calls | âœ… Supported |
| **OpenCode** | CLI Agent | HTTP API calls | âœ… Supported |
| **OpenClaw** | Extension System | HTTP API calls | âœ… Supported |
| **AutoGPT** | Fully Autonomous | HTTP API calls | âœ… Supported |
| **Custom Agents** | Any | HTTP REST API | âœ… Supported |

### Integration Pattern (Universal)

```python
# Any AI agent can use Cerebellum
import requests

CEREBELLUM_URL = "http://localhost:18080"

# 1. Assign monitoring tasks
def assign_monitoring():
    tasks = {
        "tasks": [
            {
                "id": "community-monitor",
                "type": "periodic",
                "interval": "5m",
                "command": "Check community feed for new posts"
            }
        ]
    }
    requests.post(f"{CEREBELLUM_URL}/api/tasks", json=tasks)

# 2. Execute HTTP requests through Cerebellum
def query_data(url):
    response = requests.post(
        f"{CEREBELLUM_URL}/execute",
        json={"url": url, "method": "GET"}
    )
    return response.json()

# 3. Get intelligence summaries
def get_report():
    return requests.get(f"{CEREBELLUM_URL}/api/report").json()
```

---

## Multi-Scenario Applications

### 1. Social Community Management

**Use Case**: Monitor Reddit, Discord, Moltbook, etc.

**Without Cerebellum**:
- Every feed check: 2,000 tokens
- Every trend analysis: 5,000 tokens
- Every response draft: 3,000 tokens
- **Monthly cost**: $50-100

**With Cerebellum**:
- Cerebellum monitors 24/7 locally
- Brain reviews hourly summaries: 500 tokens
- Brain writes 2-3 high-quality responses/day: 6,000 tokens
- **Monthly cost**: $3-5
- **Savings**: **90-95%**

```json
{
  "tasks": [
    {"id": "feed-monitor", "type": "periodic", "interval": "5m", "command": "Check community feed"},
    {"id": "trend-analysis", "type": "periodic", "interval": "1h", "command": "Analyze trending topics"},
    {"id": "engagement-check", "type": "periodic", "interval": "15m", "command": "Find posts needing engagement"}
  ]
}
```

### 2. GitHub Repository Monitoring

**Use Case**: Track issues, PRs, releases across multiple repos

**Without Cerebellum**:
- Check 10 repos every 30 minutes: 8,000 tokens/hour
- Analyze issues: 5,000 tokens/hour
- Draft responses: 4,000 tokens/hour
- **Monthly cost**: $120-150

**With Cerebellum**:
- Cerebellum polls GitHub API locally
- Brain reviews digest 2x/day: 1,000 tokens
- Brain handles critical issues only: 2,000 tokens
- **Monthly cost**: $10-15
- **Savings**: **90%**

```json
{
  "tasks": [
    {"id": "github-issues", "type": "periodic", "interval": "10m", "command": "Check new issues"},
    {"id": "github-prs", "type": "periodic", "interval": "15m", "command": "Monitor pull requests"},
    {"id": "release-tracker", "type": "periodic", "interval": "1h", "command": "Check for new releases"}
  ]
}
```

### 3. Customer Support Automation

**Use Case**: Monitor support tickets, forums, chat channels

**Without Cerebellum**:
- Classify 100 tickets/day: 20,000 tokens
- Draft responses: 30,000 tokens
- Escalation analysis: 10,000 tokens
- **Monthly cost**: $180-200

**With Cerebellum**:
- Cerebellum classifies locally: $0
- Brain reviews escalations only: 5,000 tokens/day
- Brain drafts complex responses: 10,000 tokens/day
- **Monthly cost**: $45-50
- **Savings**: **75%**

### 4. Market Intelligence & Research

**Use Case**: Track competitors, news, pricing changes

**Without Cerebellum**:
- Scrape 50 sources hourly: 25,000 tokens/hour
- Analyze trends: 15,000 tokens/hour
- Generate reports: 10,000 tokens/hour
- **Monthly cost**: $300-400

**With Cerebellum**:
- Cerebellum scrapes and filters locally
- Brain receives filtered insights: 3,000 tokens/day
- Brain generates strategic reports: 5,000 tokens/day
- **Monthly cost**: $25-30
- **Savings**: **90-92%**

### 5. IoT & System Monitoring

**Use Case**: Monitor server logs, metrics, alerts

**Without Cerebellum**:
- Analyze logs every 5 minutes: 15,000 tokens/hour
- Pattern detection: 8,000 tokens/hour
- Alert triage: 5,000 tokens/hour
- **Monthly cost**: $200-250

**With Cerebellum**:
- Cerebellum monitors locally
- Brain receives anomaly alerts only: 2,000 tokens/day
- **Monthly cost**: $15-20
- **Savings**: **92-94%**

---

## Token Consumption Analysis

### Detailed Cost Comparison

#### Scenario: 24/7 Community Monitoring

| Metric | Direct API (GPT-4) | With Cerebellum | Savings |
|--------|-------------------|-----------------|---------|
| **Hourly Checks** | 12 checks Ã— 2K tokens = 24K | 12 checks Ã— 0 tokens = 0 | 100% |
| **Trend Analysis** | 24 analyses Ã— 5K = 120K | 24 local = 0 | 100% |
| **Daily Summary** | 0 | 1 Ã— 1K = 1K | - |
| **Strategic Decisions** | 10 Ã— 3K = 30K | 10 Ã— 3K = 30K | 0% |
| **High-Value Responses** | 20 Ã— 4K = 80K | 5 Ã— 4K = 20K | 75% |
| **Daily Total** | **254K tokens** | **51K tokens** | **80%** |
| **Monthly Cost** | **$76.20** | **$15.30** | **$60.90 saved** |

**Annual Savings**: **$730.80**

#### Scenario: GitHub Project Management (10 repos)

| Activity | Frequency | Direct API Tokens | Cerebellum Tokens |
|----------|-----------|-------------------|-------------------|
| Issue polling | Every 10 min | 144 Ã— 1.5K = 216K | 0 |
| PR monitoring | Every 15 min | 96 Ã— 2K = 192K | 0 |
| Release checks | Every hour | 24 Ã— 1K = 24K | 0 |
| Pattern detection | Every 30 min | 48 Ã— 3K = 144K | 0 |
| Daily digest review | Once daily | 0 | 2K |
| Critical issue handling | 5/day | 5 Ã— 4K = 20K | 5 Ã— 4K = 20K |
| **Daily Total** | | **596K tokens** | **22K tokens** |
| **Monthly Cost** | | **$178.80** | **$6.60** |
| **Savings** | | | **96.3%** |

**Annual Savings**: **$2,066.40**

#### Scenario: Multi-Platform Customer Support

| Platform | Tickets/Day | Direct API Cost | Cerebellum Cost |
|----------|-------------|-----------------|-----------------|
| Email | 50 | $15/day | $3/day |
| Chat | 200 | $40/day | $8/day |
| Forum | 30 | $12/day | $2/day |
| Social Media | 100 | $25/day | $5/day |
| **Daily Total** | **380** | **$92** | **$18** |
| **Monthly Cost** | | **$2,760** | **$540** |
| **Savings** | | | **80.4%** |

**Annual Savings**: **$26,640**

---

## Architecture Deep Dive

### Why Cerebellum Saves Tokens

**1. Local Execution Model**

```
Traditional AI Agent:
User Request â†’ Main AI â†’ API Call ($) â†’ Response
                    â†“
            [Every operation costs tokens]

With Cerebellum:
User Request â†’ Cerebellum (Local LLM, $0) â†’ Raw Data
                    â†“
            Brain receives filtered summary
                    â†“
            Brain makes decision (minimal tokens)
                    â†“
            Action taken
```

**2. Task Batching**

Instead of 100 individual API calls:
- Cerebellum batches operations locally
- Sends consolidated reports to Brain
- Brain makes 1-2 decisions instead of 100

**3. Intelligent Filtering**

Cerebellum pre-filters using local LLM:
- "Is this important enough for Brain?"
- 95% of noise filtered locally
- Only 5% reaches expensive Brain API

### Performance Characteristics

| Metric | Cerebellum (Local) | Main AI (API) |
|--------|-------------------|---------------|
| **Response Time** | 50-200ms | 500-3000ms |
| **Cost per Token** | $0 | $0.01-0.03 |
| **Availability** | 100% (local) | Depends on API |
| **Rate Limits** | None | Yes |
| **Best For** | Execution, Monitoring | Strategy, Creativity |

---

## Installation & Setup

### Prerequisites

- **Ollama** installed with qwen2:0.5b model
- **Go 1.22+** (for building from source)
- Any AI agent platform (Claude Code, OpenCode, etc.)

### Quick Start

```bash
# 1. Clone repository
git clone https://github.com/yourusername/cerebellum.git
cd cerebellum

# 2. Build binary
# Windows:
go build -o bin/cerebellum.exe cmd/server/main.go

# Linux/macOS:
go build -o bin/cerebellum cmd/server/main.go

# 3. Configure
cp cerebellum.yaml.example cerebellum.yaml
# Edit cerebellum.yaml with your settings

# 4. Start Cerebellum
./bin/cerebellum

# 5. Verify
curl http://localhost:18080/health
```

### Configuration

**cerebellum.yaml**:
```yaml
server:
  host: "0.0.0.0"
  port: 18080

ollama:
  host: "http://localhost:11434"
  model: "qwen2:0.5b"  # 500M params, runs on CPU

watcher:
  poll_interval: 1000  # milliseconds
```

### Integration Example

```python
# Example: Using Cerebellum with Claude Code
import requests
import json

CEREBELLUM = "http://localhost:18080"

class CommunityManager:
    def __init__(self):
        self.setup_monitoring()
    
    def setup_monitoring(self):
        """Cerebellum handles high-frequency monitoring"""
        tasks = {
            "tasks": [
                {
                    "id": "community-feed",
                    "type": "periodic",
                    "interval": "5m",
                    "command": "Monitor community feed for new posts"
                },
                {
                    "id": "trend-detector",
                    "type": "periodic",
                    "interval": "1h",
                    "command": "Analyze trending topics"
                }
            ]
        }
        requests.post(f"{CEREBELLUM}/api/tasks", json=tasks)
    
    def check_community(self):
        """Brain reviews Cerebellum's findings"""
        report = requests.get(f"{CEREBELLUM}/api/report").json()
        
        if report["completed_count"] > 0:
            # Brain analyzes findings (expensive API call)
            findings = report["report"]["completed"]
            return self.make_strategic_decisions(findings)
        
        return "No important activity"
    
    def make_strategic_decisions(self, findings):
        """Brain makes high-value decisions"""
        # This is where GPT-4/Claude shines
        # Only called for important decisions
        pass
```

---

## Best Practices

### 1. Task Design

**Good**:
```json
{
  "id": "github-issue-monitor",
  "type": "periodic",
  "interval": "10m",
  "command": "Check for critical issues in repo"
}
```

**Bad**:
```json
{
  "id": "task1",
  "type": "monitoring",  // Wrong type!
  "interval": "5 minutes"  // Wrong format!
}
```

### 2. Interval Selection

- **Critical monitoring**: 2-5 minutes
- **Regular updates**: 15-30 minutes
- **Daily summaries**: 24 hours
- **Avoid**: All tasks at same interval (stagger them)

### 3. Cost Optimization

```
Before: 100 API calls/day Ã— $0.02 = $2.00/day = $60/month
After:  Cerebellum (100 local) + 5 API calls Ã— $0.02 = $0.10/day = $3/month
Savings: 95%
```

### 4. Security

- Cerebellum runs locally (localhost only)
- API keys never leave your machine
- Brain API calls go directly to provider
- No third-party services involved

---

## Real-World Savings Calculator

### Input Your Numbers

```python
# Your current costs
daily_api_calls = 200  # How many API calls per day
tokens_per_call = 3000  # Average tokens per call
api_cost_per_1k = 0.02  # Your API cost per 1K tokens

# Calculate
daily_tokens = daily_api_calls * tokens_per_call
daily_cost = (daily_tokens / 1000) * api_cost_per_1k
monthly_cost = daily_cost * 30

# With Cerebellum (assume 90% reduction in API calls)
cerebellum_api_calls = daily_api_calls * 0.1  # Only 10% reach Brain
cerebellum_daily_cost = (cerebellum_api_calls * tokens_per_call / 1000) * api_cost_per_1k
cerebellum_monthly = cerebellum_daily_cost * 30

savings = monthly_cost - cerebellum_monthly
savings_percent = (savings / monthly_cost) * 100

print(f"Current monthly cost: ${monthly_cost:.2f}")
print(f"With Cerebellum: ${cerebellum_monthly:.2f}")
print(f"Monthly savings: ${savings:.2f} ({savings_percent:.1f}%)")
print(f"Annual savings: ${savings * 12:.2f}")
```

### Example Output

```
Current monthly cost: $360.00
With Cerebellum: $36.00
Monthly savings: $324.00 (90.0%)
Annual savings: $3,888.00
```

---

## Comparison with Alternatives

| Solution | Cost | Latency | Setup | Flexibility |
|----------|------|---------|-------|-------------|
| **Direct API** | $$$ | Medium | Easy | High |
| **Cerebellum** | $ | Low | Medium | High |
| **Caching Layer** | $$ | Low | Medium | Low |
| **Smaller Model** | $$ | Medium | Easy | Medium |
| **Serverless Functions** | $$ | High | Complex | Medium |

**Why Cerebellum Wins**:
- Cheaper than direct API (90%+ savings)
- Faster than serverless (local execution)
- More flexible than caching (intelligent filtering)
- Better than smaller model (keeps Brain's quality)

---

## FAQ

**Q: Does Cerebellum replace my main AI?**
A: No! It complements it. Cerebellum handles execution; Brain handles strategy.

**Q: What LLM does Cerebellum use?**
A: Default is qwen2:0.5b via Ollama (free, local). You can configure other models.

**Q: How much can I really save?**
A: Typical savings are 80-95% for high-frequency monitoring tasks.

**Q: Is it hard to set up?**
A: Single binary, one config file. 5 minutes to get running.

**Q: Does it work with my existing agent?**
A: Yes! Any agent that can make HTTP calls can use Cerebellum.

**Q: What about data privacy?**
A: Everything runs locally. Your data never leaves your machine except for final Brain API calls.

---

## Contributing

We welcome contributions from the AI agent community!

- Report issues
- Submit PRs
- Share your use cases
- Suggest improvements

---

## License

Apache License 2.0 - Free for personal and commercial use.

---

## Acknowledgments

Built for the AI agent community. Special thanks to:
- Ollama team for local LLM inference
- All AI agent platforms pushing the boundaries
- Early adopters and contributors

---

**Start saving tokens today. Deploy Cerebellum.**

*"Let Cerebellum handle the noise. Let Brain handle the signal."*

---

**Version**: 1.0  
**Last Updated**: 2026-02-09  
**Status**: Production Ready âœ…  
http://Cerebellum.openx.pro
https://github.com/ChengDuBJUT